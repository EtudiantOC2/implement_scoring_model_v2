{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 7 : Implémentez un modèle de scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous êtes Data Scientist au sein d'une société financière, nommée \"Prêt à dépenser\",  qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
    "\n",
    "L’entreprise souhaite **mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse ou non son crédit**, **puis classifie la demande en crédit accordé ou refusé**. Elle souhaite donc développer un algorithme de classification en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.).\n",
    "\n",
    "De plus, les chargés de relation client ont fait remonter le fait que les clients sont de plus en plus demandeurs de transparence vis-à-vis des décisions d’octroi de crédit. Cette demande de transparence des clients va tout à fait dans le sens des valeurs que l’entreprise veut incarner.\n",
    "\n",
    "**Prêt à dépenser décide donc de développer un dashboard interactif pour que les chargés de relation client puissent à la fois expliquer de façon la plus transparente possible les décisions d’octroi de crédit, mais également permettre à leurs clients de disposer de leurs informations personnelles et de les explorer facilement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mise en place de l'environnement virtuel\n",
    "- Modélisation\n",
    " - Cadre de la modélisation\n",
    " - Choix du meilleur modèle de classification\n",
    "   - Régression Logistique\n",
    "   - SVM\n",
    "   - Forêt Aléatoire\n",
    "  - Mise en oeuvre du modèle et enregistrement des résultats\n",
    "  - Features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place de l'environnement virtuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics,model_selection,preprocessing,linear_model,svm\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score,precision_score, recall_score, f1_score, fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se situe ici dans un **problème d'apprentissage de classification supervisée** ; l'objectif est d'utiliser un ensemble de données financières et socio-économiques pour **prédire si un demandeur sera en mesure de rembourser un prêt ou non**\n",
    "- **supervisée** : les valeurs cibles à prédire sont \"déjà\" incluses dans nos données d'apprentissage et l'objectif est de former un modèle pour apprendre à prédire ces valeurs cibles à partir des différents features\n",
    "- **classification** : la valeur cible est une variable binaire ; 0 signifie que le client remboursera le prêt à temps et 1 signifie que le client aura au contraire des difficultés à rembourser le prêt (ici on parle de **classification binaire** : il s'agit en fait de distinguer si un prêt appartient ou non à une classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadre de la modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Données utilisées*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\pauline_castoriadis\\\\Documents\\\\implement_scoring_model\\\\data\\\\df_train.csv', sep=',')\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problèmatique du déséquilibre*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se rappelle ici qu'on se trouve face à **un problème déséquilibré** : en effet (et heureusement), il **existe davantage de crédits remboursés (valeur 0) que de crédits non remboursés (valeur 1)** ; notre objectif reste bien de **classifier au plus juste ces clients qui ont une forte probabilité de ne pas rembourser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    282686\n",
       "1.0     24825\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des algorithmes d'apprentissage automatique fonctionnent mieux **lorsque le nombre d'échantillons dans chaque classe est à peu près égal** : cela s'explique par le fait que la plupart des algorithmes sont conçus pour maximiser la précision et réduire les erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plusieurs options s'offrent à nous** : \n",
    "- Collecter plus de données sur la classe minoritaire\n",
    "- Réduire le nombre d’individus dans la classe majoritaire\n",
    "- Dupliquer des individus sous-représentés\n",
    "- Choix d’une métrique de performance adaptée (on sait qu'on veut traiter plus préciser des faux négatifs)\n",
    "- Création d’individus « synthétiques »\n",
    "- Pondération des observations dans le training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Préparation des données*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre base de données, ainsi nettoyée et explorée dans le précédent notebook, contient près de **350k demandes de prêts** et une **trentaine de variables**, dont notre variable cible (la **variable \"target\"**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cible = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mettant de côté la variable id (\"applicant_loan_id\") et la variable qui nous permettra de séparer les sets de données (\"type_of_set\"), on rappelle qu'on a donc mis en place **27 variables prédictrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_prédictrices =  list(df.loc[:, (df.columns != 'applicant_loan_id') & (df.columns != 'type_of_set') & (df.columns != cible)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choix de la meilleure metric d'évaluation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'évaluer la performance de notre classification, nous avons plusieurs outils à notre disposition :\n",
    "- **Matrice de confusion** : en fonction des valeurs prises par nos classes **réelles** et nos classes **prédites**, on peut calculer le nombre de **faux positifs** et de **faux négatifs** puis de **vrais positifs** et de **vrais négatifs**\n",
    "- **Rapport de classification** : permet de mettre en évidence les indicateurs suivants\n",
    "  - **Rappel/sensibilité** (recall/sensitivity): **taux de vrais positifs** ; il s'agit de la proportion de positifs que l’on a correctement identifié (capacité de notre modèle à identifier tous les gens qui ne seraient pas capables de rembourser leur prêt)\n",
    "  - **Précision** (accuracy) : proportion de prédictions correctes parmi les points que l’on a prédits positifs\n",
    "  - **F-mesure** : **moyenne harmonique du rappel et de la précision**\n",
    "  - **Spécificité** (specificity) : **taux de vrais négatifs** (mesure complémentaire de la sensibilité)\n",
    "- **Courbe ROC** : par une courbe, permet de comprendre comment la sensibilité évolue en fonction de la spécificité (pour chaque seuil de décision possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons **mettre en place le f beta score, qui permet d'identifier un bon compromis entre précision et recall** (sachant qu'il n'existe pas de taux précis pour identifier les faux négatifs, il faut trouver un moyen détourné)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_scorer(fbeta_score, beta = 2.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Séparation jeu d'entrainement et jeu de test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n = 10000) # Echantillon pour faire tourner jusqu'au bout le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède à une **séparation de nos données au sein de notre jeu de données d'entrainement pour obtenir la validation de la bonne performance de notre modèle de machine learning** (en plus du fait que les étiquettes attribuées à chaque client sont déjà présentes uniquement dans le jeu d'entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[variables_prédictrices].values\n",
    "y = df[cible].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 7326, 1.0: 7326})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mise à l'échelle des données*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus de séparer nos données en données d'entrainement et de test, il faut ramener à une échelle similaire nos différentes données (qui sont de natures extremement différentes) ; **on applique ce traitement uniquement à nos variables prédictrices** (**méthode de standardisation des données**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du meilleur modèle de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression logistique est un algorithme utilisé pour les problèmes de classification, c'est un algorithme d'analyse prédictive et basé sur le **concept de probabilité**. Nous pouvons appeler une régression logistique un modèle de régression linéaire mais la régression logistique utilise une fonction de coût plus complexe, cette fonction de coût peut être définie comme la « fonction sigmoïde » ou également connue sous le nom de « fonction logistique » au lieu d'une fonction linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'hypothèse de régression logistique tend à limiter la fonction de coût entre 0 et 1. Par conséquent, les fonctions linéaires ne parviennent pas à le représenter car il peut avoir une valeur supérieure à 1 ou inférieure à 0, ce qui n'est pas possible selon l'hypothèse de la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': 42,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "lr_0 = LogisticRegression(random_state = 42)\n",
    "pprint(lr_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons régler les hyperparamètres suivants :\n",
    "- **C** = Inverse de la force de régularisation (des valeurs plus petites indiquent une régularisation plus forte)\n",
    "- **solver** = Algorithme à utiliser pour le problème d'optimisation. Pour les problèmes multi-classes, seuls newton-cg, sag, saga et lbfgs gèrent la perte multinomiale\n",
    "- **class_weight** = Poids associés aux classes (pour traiter en amont le potentiel problème de déséquilibre)\n",
    "- **penalty** = Utilisé pour spécifier la norme utilisée dans la pénalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [100, 10, 1.0, 0.5, 0.1, 0.01]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "class_weight = ['balanced']\n",
    "penalty = ['none', 'l1', 'l2', 'elasticnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {'C': C,'solver': solver,'class_weight': class_weight,'penalty': penalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'instant, on réalise simplement la mesure de la performance de notre modèle dans sa capacité à prédire la bonne catégorie binaire (0 ou 1 ici simplement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_perf (X_train,X_test,y_train,y_test,modèle,param_grid,score,titre):\n",
    "    \"\"\"\n",
    "    Recherche les meilleurs hyperparamètres\n",
    "    Entraine et analyse les performances du modèle à partir du jeu d'entrainement\n",
    "    \"\"\"\n",
    "    # Application sur le modèle\n",
    "    clf = model_selection.GridSearchCV(modèle,param_grid,cv = 10,scoring = score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Afficher le(s) hyperparamètre(s) optimaux\n",
    "    print(\"\\nMeilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    # Mise en oeuvre du modèle avec les meilleurs paramètres\n",
    "    clf = clf.best_estimator_\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Calculs des indicateurs permettant de qualifier la qualité du modèle, sur le jeu d'entrainement\n",
    "    temps_calcul = end - start\n",
    "    y_pred = clf.predict(X_train)\n",
    "    fbeta = fbeta_score(y_train, y_pred, average = 'weighted', beta = 0.5)\n",
    "    recall = recall_score(y_train, y_pred, average = 'weighted')\n",
    "    precision = precision_score(y_train, y_pred, average = 'weighted')\n",
    "    \n",
    "    # Mise en forme sous format dataframe\n",
    "    df_indicateurs = pd.DataFrame()\n",
    "    \n",
    "    # Résultats sous format dataframe\n",
    "    df_indicateurs.loc[1, \"Modèle\"] = titre\n",
    "    df_indicateurs.loc[1, \"temps calcul\"] = temps_calcul\n",
    "    df_indicateurs.loc[1, \"fbeta_score\"] = round(fbeta, 2)\n",
    "    df_indicateurs.loc[1, \"recall\"] = round(recall, 2)\n",
    "    df_indicateurs.loc[1, \"precision\"] = round(precision, 2)\n",
    "    \n",
    "    return df_indicateurs.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "table_lr = set_model_perf(X_train,X_test,y_train,y_test,lr_model,lr_param_grid,score,'Régression logistique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>temps calcul</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Régression logistique</td>\n",
       "      <td>0.039444</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modèle  temps calcul  fbeta_score  recall  precision\n",
       "0  Régression logistique      0.039444         0.66    0.66       0.66"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les algorithmes SVM sont :\n",
    "- Utilisés pour des problèmes de classification\n",
    "- Généralement utilisé pour un ensemble de données plus petit car il prend du temps à traiter les données\n",
    "- **C'est l'idée de trouver un hyperplan qui sépare au mieux les caractéristiques en différents domaines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamètres possibles et leurs valeurs par défaut:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': False,\n",
      " 'random_state': 42,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "svc_0 = svm.SVC(random_state = 42)\n",
    "print('Hyperparamètres possibles et leurs valeurs par défaut:\\n')\n",
    "pprint(svc_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons régler les hyperparamètres suivants :\n",
    "- **C** = Paramètre de pénalité C du terme d'erreur\n",
    "- **kernel** = Spécifie le type de noyau à utiliser dans l'algorithme\n",
    "- **class_weight** = Même problématique que précédemment\n",
    "- **gamma** = Coefficient du noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [.001, .01]\n",
    "gamma = [.01, .1, 1, 10]\n",
    "class_weight = ['balanced']\n",
    "kernel = ['linear', 'rbf', 'poly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': C,'kernel': kernel,'gamma': gamma,'class_weight': class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "table_svm = set_model_perf(X_train,X_test,y_train,y_test,svm_model,svm_param_grid,score,'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>temps calcul</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>159.380898</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  temps calcul  fbeta_score  recall  precision\n",
       "0    SVM    159.380898         0.97    0.97       0.97"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forêt aléatoire se base sur un grand nombre d'abres de décision individuels qui fonctionnent comme un ensemble (il s'agit d'un modèle de la famille des algorithmes ensemblistes, mais qui fonctionnent en parallèle et non pas de manière séquentielle via les apprenants faibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamètres possibles et leurs valeurs par défaut:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_0 = RandomForestClassifier(random_state = 42)\n",
    "print('Hyperparamètres possibles et leurs valeurs par défaut:\\n')\n",
    "pprint(rf_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons régler les hyperparamètres suivants :\n",
    "- **n_estimators** = nombre d'arbres dans la forêt (nombre d'apprenants faibles)\n",
    "- **max_depth** = nombre maximum de niveaux dans chaque arbre de décision (profondeur de chaque arbre)\n",
    "- **bootstrap** = méthode d'échantillonnage des points de données (avec ou sans remplacement)\n",
    "- **class_weight** = même chose que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100,500,1000]\n",
    "class_weight = ['balanced']\n",
    "max_depth = [3,5,10,15]\n",
    "bootstrap = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {'n_estimators': n_estimators,'max_depth': max_depth,'bootstrap': bootstrap,\n",
    "                 'class_weight' : class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 15, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "table_rf = set_model_perf(X_train,X_test,y_train,y_test,rf_model,rf_param_grid,score,'Forêt Aléatoire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>temps calcul</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forêt Aléatoire</td>\n",
       "      <td>70.36445</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Modèle  temps calcul  fbeta_score  recall  precision\n",
       "0  Forêt Aléatoire      70.36445         0.99    0.99       0.99"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en oeuvre du modèle et enregistrement des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>temps calcul</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Régression logistique</td>\n",
       "      <td>0.039444</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>159.380898</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forêt Aléatoire</td>\n",
       "      <td>70.364450</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modèle  temps calcul  fbeta_score  recall  precision\n",
       "0  Régression logistique      0.039444         0.66    0.66       0.66\n",
       "0                    SVM    159.380898         0.97    0.97       0.97\n",
       "0        Forêt Aléatoire     70.364450         0.99    0.99       0.99"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [table_lr, table_svm, table_rf]\n",
    "result = pd.concat(frames)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basé sur la performance du fbeta_score, on sélectionne **le meilleur modèle pour ce problème**, ainsi que ses **meilleurs hyperparamètres** (la meilleure combinaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators = 1000,max_depth = 15 ,bootstrap = 'True' ,class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9895899367272645\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train,y_train)\n",
    "predict_train = best_model.predict(X_train)\n",
    "fbeta = fbeta_score(y_train, predict_train, average = 'weighted', beta = 0.5)\n",
    "print(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_test,y_test)\n",
    "predict_test = best_model.predict(X_test)\n",
    "fbeta = fbeta_score(y_test, predict_test, average = 'weighted', beta = 0.5)\n",
    "print(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86452889, 0.13547111],\n",
       "       [0.83443777, 0.16556223],\n",
       "       [0.861     , 0.139     ],\n",
       "       ...,\n",
       "       [0.85835916, 0.14164084],\n",
       "       [0.86209864, 0.13790136],\n",
       "       [0.84467593, 0.15532407]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = best_model.predict_proba(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\pauline_castoriadis\\\\Documents\\\\implement_scoring_model\\\\model\\\\best_model.pkl', 'wb') as files:\n",
    "    pickle.dump(best_model, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertinence des features utilisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus d'obtenir d'obtenir un modèle précis, on veut avoir un **modèle interprétable**, c'est à dire être en mesure d'**identifier les variables les plus importantes** (ie. les caractéristiques les plus importantes pour expliquer la variable cible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Poids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bureau_seniority_past_loans</td>\n",
       "      <td>0.087814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>applicant_age</td>\n",
       "      <td>0.084926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>annuity_share_to_income</td>\n",
       "      <td>0.084655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>previous_application_accepted_share</td>\n",
       "      <td>0.082530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>previous_application_credit_term</td>\n",
       "      <td>0.077866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_credit_amount</td>\n",
       "      <td>0.072737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>level_pop_living_region</td>\n",
       "      <td>0.070891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applicant_total_income</td>\n",
       "      <td>0.058305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>applicant_occupation</td>\n",
       "      <td>0.047865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bureau_count_past_loans</td>\n",
       "      <td>0.045882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature     Poids\n",
       "17          bureau_seniority_past_loans  0.087814\n",
       "12                        applicant_age  0.084926\n",
       "13              annuity_share_to_income  0.084655\n",
       "22  previous_application_accepted_share  0.082530\n",
       "23     previous_application_credit_term  0.077866\n",
       "4                   total_credit_amount  0.072737\n",
       "8               level_pop_living_region  0.070891\n",
       "3                applicant_total_income  0.058305\n",
       "9                  applicant_occupation  0.047865\n",
       "15              bureau_count_past_loans  0.045882"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame()\n",
    "importance[\"Feature\"] = variables_prédictrices\n",
    "importance[\"Poids\"] = best_model.feature_importances_\n",
    "importance.sort_values(\"Poids\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi observer que l'âge du demandeur de prêt a une forte importance dans notre modèle ; ces informations nous seront très utiles pour savoir quelles variables mettre en avant dans notre dashboard streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valeurs de Shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer ces valeurs présente trois avantages principaux :\n",
    "- Le premier est **l'interprétabilité globale** - les valeurs SHAP collectives peuvent montrer **dans quelle mesure chaque prédicteur contribue, positivement ou négativement, à la variable cible**\n",
    "- Le deuxième avantage est **l'interprétabilité locale** - chaque observation obtient son propre ensemble de valeurs SHAP (on peut expliquer pourquoi un individu reçoit sa prédiction et les contributions des prédicteurs)\n",
    "- Troisièmement, **les valeurs SHAP peuvent être calculées pour n'importe quel modèle basé sur un arbre**, tandis que d'autres méthodes utilisent des modèles de régression linéaire ou de régression logistique comme modèles de substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interprétabilité globale*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(best_model).shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on peut lire les informations suivantes :\n",
    "- **Importance des caractéristiques** : les variables sont classées par ordre décroissant (les plus importantes pour nous se situent en haut)\n",
    "- **Impact** : l'emplacement horizontal indique si l'effet de cette valeur est associé à une prédiction supérieure ou inférieure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interprétabilité locale*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_shap_interpretability(values,individual):\n",
    "    \"\"\"\"\n",
    "    Permet de donner par individu sélectionné l'interprétabilité locale des valeurs de shapley\n",
    "    \"\"\"\n",
    "    data = values[individual]\n",
    "    array = data.reshape(1, -1)\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(data)\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(explainer.expected_value[individual], shap_values[individual], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_shap_interpretability(X,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
